{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST-MultiLayer-NN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishwashrisairam/AI-Workshop/blob/master/MNIST_MultiLayer_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHJpgGknvgFv",
        "colab_type": "text"
      },
      "source": [
        "## Layout \n",
        "1. Define Parameters\n",
        "2. TF Computation Graph \n",
        "3. Multilayer perceptron\n",
        "4. W,b Dictionaries \n",
        "5. Pred Label  \n",
        "6. Cost and Optimizers \n",
        "7. Init Session \n",
        "8. Run the session and the model \n",
        "9. Eval accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aueYT5sf6UXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "b40c859b-3802-4a60-b9a8-07099a9537ba"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.4)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (42.0.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HftsMEfzuP1B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "3a186b90-ee01-41dc-af69-6b858cb08f69"
      },
      "source": [
        "# Step 1 \n",
        "import tensorflow as tf "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaEkXy6GwrJ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "cbcf41ed-cf3c-4147-adb7-9dcfc997365a"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist=input_data.read_data_sets(\"MNIST_data\",one_hot=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-889645637461>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWFN0c0KwwBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hyper Parameters \n",
        "learning_rate=0.001\n",
        "training_epochs=250\n",
        "batch_size=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6BKoo-DxSYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Network Parameters \n",
        "n_hidden1 = 256\n",
        "n_hidden2 = 256\n",
        "n_hidden3 = 256\n",
        "n_input   = 784\n",
        "n_classes = 10\n",
        "n_samples = mnist.train.num_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJhGeJYCxsTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TF Graph placeholders \n",
        "x = tf.placeholder(\"float\",[None,n_input])\n",
        "y = tf.placeholder(\"float\",[None,n_classes])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQgXMRV5zEVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#weights and biases \n",
        "weights={\n",
        "    'h1':tf.Variable(tf.random_normal([n_input,n_hidden1])),\n",
        "    'h2':tf.Variable(tf.random_normal([n_hidden1,n_hidden2])),\n",
        "    'h3':tf.Variable(tf.random_normal([n_hidden2,n_hidden3])),\n",
        "    'out':tf.Variable(tf.random_normal([n_hidden3,n_classes]))\n",
        "}\n",
        "\n",
        "biases={\n",
        "    'b1':tf.Variable(tf.random_normal([n_hidden1])),\n",
        "    'b2':tf.Variable(tf.random_normal([n_hidden2])),\n",
        "    'b3':tf.Variable(tf.random_normal([n_hidden3])),\n",
        "    'out':tf.Variable(tf.random_normal([n_classes]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3U8eyWYyAnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MLP \n",
        "def mlp(x,weights,biases): \n",
        "  layer_1= tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
        "  layer_1= tf.nn.relu(layer_1)\n",
        "\n",
        "  layer_2= tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
        "  layer_2= tf.nn.relu(layer_2)\n",
        "\n",
        "  #final output \n",
        "  out_layer=tf.add(tf.matmul(layer_2,weights['out']),biases['out'])\n",
        "  return out_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZZtWE9xA89F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MLP \n",
        "def mlp3l(x,weights,biases): \n",
        "  layer_1= tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
        "  layer_1= tf.nn.relu(layer_1)\n",
        "\n",
        "  layer_2= tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
        "  layer_2= tf.nn.relu(layer_2)\n",
        "\n",
        "  layer_3= tf.add(tf.matmul(layer_2,weights['h3']),biases['b3'])\n",
        "  layer_3= tf.nn.relu(layer_3)\n",
        "\n",
        "  #final output \n",
        "  out_layer=tf.add(tf.matmul(layer_3,weights['out']),biases['out'])\n",
        "  return out_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI60GUcL0h8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predicted Label \n",
        "# pred=mlp(x,weights,biases)\n",
        "pred=mlp3l(x,weights,biases)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l32YlaWM3bZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #costs / optimizers\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y,\n",
        "                                                                logits = pred))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPXzMBZ-2w4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbrdgt9L1Zo-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "27d577ce-c023-4d03-cf09-9269733d7e0c"
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "\n",
        "sess.run(init)\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "  avg_cost=0.0\n",
        "  total_batch= int(n_samples/batch_size)\n",
        "\n",
        "  #Loop over all batches \n",
        "  for i in range(total_batch):\n",
        "    batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
        "\n",
        "    #feed the dict to minimize & optimize the cost \n",
        "    _,c=sess.run([optimizer,cost],feed_dict={x:batch_x,y:batch_y})\n",
        "\n",
        "    #Compute avg loss \n",
        "    avg_cost += c / total_batch\n",
        "  print(\"Epoch: {} cost={: .4f}\".format(epoch+1,avg_cost))\n",
        "\n",
        "print(\"Model has completed {} Epochs of training\".format(training_epochs))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 cost= 1279.3743\n",
            "Epoch: 2 cost= 279.3457\n",
            "Epoch: 3 cost= 161.7222\n",
            "Epoch: 4 cost= 103.1075\n",
            "Epoch: 5 cost= 69.0753\n",
            "Epoch: 6 cost= 47.2908\n",
            "Epoch: 7 cost= 31.3582\n",
            "Epoch: 8 cost= 23.3612\n",
            "Epoch: 9 cost= 17.6223\n",
            "Epoch: 10 cost= 13.0889\n",
            "Epoch: 11 cost= 11.4745\n",
            "Epoch: 12 cost= 9.3304\n",
            "Epoch: 13 cost= 7.6904\n",
            "Epoch: 14 cost= 7.8710\n",
            "Epoch: 15 cost= 7.0215\n",
            "Epoch: 16 cost= 5.8884\n",
            "Epoch: 17 cost= 5.3699\n",
            "Epoch: 18 cost= 5.8356\n",
            "Epoch: 19 cost= 4.6774\n",
            "Epoch: 20 cost= 4.5212\n",
            "Epoch: 21 cost= 4.6766\n",
            "Epoch: 22 cost= 4.6061\n",
            "Epoch: 23 cost= 4.0739\n",
            "Epoch: 24 cost= 3.6359\n",
            "Epoch: 25 cost= 4.0283\n",
            "Epoch: 26 cost= 3.4596\n",
            "Epoch: 27 cost= 3.7951\n",
            "Epoch: 28 cost= 3.7149\n",
            "Epoch: 29 cost= 4.2032\n",
            "Epoch: 30 cost= 2.8753\n",
            "Epoch: 31 cost= 2.9719\n",
            "Epoch: 32 cost= 3.1770\n",
            "Epoch: 33 cost= 2.8323\n",
            "Epoch: 34 cost= 3.0301\n",
            "Epoch: 35 cost= 2.5988\n",
            "Epoch: 36 cost= 2.4466\n",
            "Epoch: 37 cost= 2.5493\n",
            "Epoch: 38 cost= 3.3657\n",
            "Epoch: 39 cost= 2.6336\n",
            "Epoch: 40 cost= 2.8394\n",
            "Epoch: 41 cost= 2.4854\n",
            "Epoch: 42 cost= 2.8577\n",
            "Epoch: 43 cost= 2.3287\n",
            "Epoch: 44 cost= 2.0992\n",
            "Epoch: 45 cost= 2.4847\n",
            "Epoch: 46 cost= 1.9937\n",
            "Epoch: 47 cost= 2.1878\n",
            "Epoch: 48 cost= 2.3815\n",
            "Epoch: 49 cost= 2.4376\n",
            "Epoch: 50 cost= 2.2942\n",
            "Epoch: 51 cost= 1.7144\n",
            "Epoch: 52 cost= 2.1510\n",
            "Epoch: 53 cost= 2.2918\n",
            "Epoch: 54 cost= 1.8367\n",
            "Epoch: 55 cost= 2.2972\n",
            "Epoch: 56 cost= 1.7753\n",
            "Epoch: 57 cost= 1.8638\n",
            "Epoch: 58 cost= 2.2336\n",
            "Epoch: 59 cost= 1.2854\n",
            "Epoch: 60 cost= 1.8733\n",
            "Epoch: 61 cost= 1.8813\n",
            "Epoch: 62 cost= 1.5316\n",
            "Epoch: 63 cost= 1.6351\n",
            "Epoch: 64 cost= 2.0804\n",
            "Epoch: 65 cost= 1.2006\n",
            "Epoch: 66 cost= 1.6237\n",
            "Epoch: 67 cost= 1.5539\n",
            "Epoch: 68 cost= 2.1837\n",
            "Epoch: 69 cost= 1.8959\n",
            "Epoch: 70 cost= 1.6996\n",
            "Epoch: 71 cost= 0.9904\n",
            "Epoch: 72 cost= 2.0946\n",
            "Epoch: 73 cost= 1.2184\n",
            "Epoch: 74 cost= 2.2120\n",
            "Epoch: 75 cost= 1.7580\n",
            "Epoch: 76 cost= 1.6375\n",
            "Epoch: 77 cost= 0.9766\n",
            "Epoch: 78 cost= 2.0865\n",
            "Epoch: 79 cost= 1.4974\n",
            "Epoch: 80 cost= 1.8067\n",
            "Epoch: 81 cost= 1.7422\n",
            "Epoch: 82 cost= 1.4634\n",
            "Epoch: 83 cost= 1.2195\n",
            "Epoch: 84 cost= 1.2810\n",
            "Epoch: 85 cost= 1.1934\n",
            "Epoch: 86 cost= 1.1239\n",
            "Epoch: 87 cost= 1.6906\n",
            "Epoch: 88 cost= 1.4583\n",
            "Epoch: 89 cost= 1.0368\n",
            "Epoch: 90 cost= 1.2539\n",
            "Epoch: 91 cost= 1.2467\n",
            "Epoch: 92 cost= 2.1759\n",
            "Epoch: 93 cost= 0.7031\n",
            "Epoch: 94 cost= 0.7812\n",
            "Epoch: 95 cost= 1.9453\n",
            "Epoch: 96 cost= 1.3223\n",
            "Epoch: 97 cost= 1.0615\n",
            "Epoch: 98 cost= 0.9885\n",
            "Epoch: 99 cost= 1.3394\n",
            "Epoch: 100 cost= 0.7957\n",
            "Epoch: 101 cost= 1.5684\n",
            "Epoch: 102 cost= 0.9309\n",
            "Epoch: 103 cost= 1.4156\n",
            "Epoch: 104 cost= 1.1302\n",
            "Epoch: 105 cost= 1.4994\n",
            "Epoch: 106 cost= 0.9671\n",
            "Epoch: 107 cost= 0.6625\n",
            "Epoch: 108 cost= 2.0400\n",
            "Epoch: 109 cost= 1.1387\n",
            "Epoch: 110 cost= 0.9387\n",
            "Epoch: 111 cost= 1.3264\n",
            "Epoch: 112 cost= 1.0605\n",
            "Epoch: 113 cost= 1.4507\n",
            "Epoch: 114 cost= 1.0433\n",
            "Epoch: 115 cost= 0.9596\n",
            "Epoch: 116 cost= 1.4337\n",
            "Epoch: 117 cost= 1.0419\n",
            "Epoch: 118 cost= 0.9419\n",
            "Epoch: 119 cost= 0.7894\n",
            "Epoch: 120 cost= 0.8717\n",
            "Epoch: 121 cost= 1.1939\n",
            "Epoch: 122 cost= 1.4948\n",
            "Epoch: 123 cost= 0.4774\n",
            "Epoch: 124 cost= 1.0777\n",
            "Epoch: 125 cost= 1.2296\n",
            "Epoch: 126 cost= 0.8279\n",
            "Epoch: 127 cost= 1.2561\n",
            "Epoch: 128 cost= 1.2015\n",
            "Epoch: 129 cost= 0.9949\n",
            "Epoch: 130 cost= 1.5453\n",
            "Epoch: 131 cost= 0.4378\n",
            "Epoch: 132 cost= 1.0337\n",
            "Epoch: 133 cost= 0.9732\n",
            "Epoch: 134 cost= 1.0332\n",
            "Epoch: 135 cost= 1.3279\n",
            "Epoch: 136 cost= 0.7305\n",
            "Epoch: 137 cost= 1.3783\n",
            "Epoch: 138 cost= 1.1115\n",
            "Epoch: 139 cost= 1.1863\n",
            "Epoch: 140 cost= 0.8699\n",
            "Epoch: 141 cost= 1.1723\n",
            "Epoch: 142 cost= 1.0662\n",
            "Epoch: 143 cost= 1.1485\n",
            "Epoch: 144 cost= 0.8497\n",
            "Epoch: 145 cost= 0.4808\n",
            "Epoch: 146 cost= 1.2721\n",
            "Epoch: 147 cost= 1.2732\n",
            "Epoch: 148 cost= 1.0364\n",
            "Epoch: 149 cost= 0.7289\n",
            "Epoch: 150 cost= 0.7787\n",
            "Epoch: 151 cost= 0.5907\n",
            "Epoch: 152 cost= 1.3594\n",
            "Epoch: 153 cost= 0.8079\n",
            "Epoch: 154 cost= 0.7754\n",
            "Epoch: 155 cost= 1.0099\n",
            "Epoch: 156 cost= 1.0347\n",
            "Epoch: 157 cost= 0.8994\n",
            "Epoch: 158 cost= 0.9616\n",
            "Epoch: 159 cost= 1.1007\n",
            "Epoch: 160 cost= 1.1663\n",
            "Epoch: 161 cost= 0.6398\n",
            "Epoch: 162 cost= 0.7086\n",
            "Epoch: 163 cost= 0.9717\n",
            "Epoch: 164 cost= 0.5534\n",
            "Epoch: 165 cost= 0.8207\n",
            "Epoch: 166 cost= 1.1964\n",
            "Epoch: 167 cost= 0.3468\n",
            "Epoch: 168 cost= 1.5925\n",
            "Epoch: 169 cost= 0.8327\n",
            "Epoch: 170 cost= 0.7314\n",
            "Epoch: 171 cost= 1.0616\n",
            "Epoch: 172 cost= 0.6322\n",
            "Epoch: 173 cost= 0.8271\n",
            "Epoch: 174 cost= 1.0734\n",
            "Epoch: 175 cost= 1.0813\n",
            "Epoch: 176 cost= 0.8435\n",
            "Epoch: 177 cost= 0.7212\n",
            "Epoch: 178 cost= 0.6120\n",
            "Epoch: 179 cost= 0.8632\n",
            "Epoch: 180 cost= 1.2897\n",
            "Epoch: 181 cost= 0.9239\n",
            "Epoch: 182 cost= 0.5146\n",
            "Epoch: 183 cost= 1.0852\n",
            "Epoch: 184 cost= 0.7686\n",
            "Epoch: 185 cost= 0.8313\n",
            "Epoch: 186 cost= 1.1185\n",
            "Epoch: 187 cost= 0.7365\n",
            "Epoch: 188 cost= 0.6412\n",
            "Epoch: 189 cost= 0.6231\n",
            "Epoch: 190 cost= 1.0223\n",
            "Epoch: 191 cost= 0.6055\n",
            "Epoch: 192 cost= 1.6363\n",
            "Epoch: 193 cost= 0.4645\n",
            "Epoch: 194 cost= 0.6496\n",
            "Epoch: 195 cost= 1.2780\n",
            "Epoch: 196 cost= 0.6446\n",
            "Epoch: 197 cost= 1.0037\n",
            "Epoch: 198 cost= 0.4559\n",
            "Epoch: 199 cost= 0.7430\n",
            "Epoch: 200 cost= 1.0651\n",
            "Epoch: 201 cost= 0.7420\n",
            "Epoch: 202 cost= 0.6587\n",
            "Epoch: 203 cost= 0.9270\n",
            "Epoch: 204 cost= 0.6992\n",
            "Epoch: 205 cost= 0.9104\n",
            "Epoch: 206 cost= 0.7155\n",
            "Epoch: 207 cost= 1.0636\n",
            "Epoch: 208 cost= 0.6177\n",
            "Epoch: 209 cost= 0.7245\n",
            "Epoch: 210 cost= 0.7908\n",
            "Epoch: 211 cost= 1.1777\n",
            "Epoch: 212 cost= 0.4452\n",
            "Epoch: 213 cost= 0.5697\n",
            "Epoch: 214 cost= 0.9889\n",
            "Epoch: 215 cost= 0.4597\n",
            "Epoch: 216 cost= 0.7140\n",
            "Epoch: 217 cost= 0.7138\n",
            "Epoch: 218 cost= 0.7220\n",
            "Epoch: 219 cost= 1.1387\n",
            "Epoch: 220 cost= 0.5688\n",
            "Epoch: 221 cost= 0.5923\n",
            "Epoch: 222 cost= 0.8774\n",
            "Epoch: 223 cost= 0.5030\n",
            "Epoch: 224 cost= 0.9903\n",
            "Epoch: 225 cost= 0.4540\n",
            "Epoch: 226 cost= 0.7359\n",
            "Epoch: 227 cost= 1.0755\n",
            "Epoch: 228 cost= 0.7213\n",
            "Epoch: 229 cost= 0.7122\n",
            "Epoch: 230 cost= 0.8528\n",
            "Epoch: 231 cost= 0.6666\n",
            "Epoch: 232 cost= 0.8727\n",
            "Epoch: 233 cost= 0.9859\n",
            "Epoch: 234 cost= 1.2753\n",
            "Epoch: 235 cost= 0.3351\n",
            "Epoch: 236 cost= 0.5415\n",
            "Epoch: 237 cost= 0.4683\n",
            "Epoch: 238 cost= 0.5679\n",
            "Epoch: 239 cost= 0.7461\n",
            "Epoch: 240 cost= 1.1879\n",
            "Epoch: 241 cost= 0.6537\n",
            "Epoch: 242 cost= 0.6479\n",
            "Epoch: 243 cost= 0.1947\n",
            "Epoch: 244 cost= 0.8123\n",
            "Epoch: 245 cost= 0.3521\n",
            "Epoch: 246 cost= 0.8735\n",
            "Epoch: 247 cost= 0.8951\n",
            "Epoch: 248 cost= 1.2431\n",
            "Epoch: 249 cost= 0.2662\n",
            "Epoch: 250 cost= 0.2054\n",
            "Model has completed 250 Epochs of training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z3ibBe-4Pb0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "31639abc-6c62-4059-a5cf-8032b35114e7"
      },
      "source": [
        "#model testing and predictions \n",
        "correct_predictions = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
        "print(correct_predictions[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"strided_slice:0\", shape=(), dtype=bool)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pztnye6N5nwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_predictions=tf.cast(correct_predictions,\"float\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftNhs-U85vVm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9b4ef294-18ee-424a-f8a7-6a01e3f93654"
      },
      "source": [
        "accuracy=tf.reduce_mean(correct_predictions)\n",
        "print(\"Accuracy:\",accuracy.eval({x:mnist.test.images,y:mnist.test.labels}))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9763\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}